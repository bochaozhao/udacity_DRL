{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, I used the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Import necessary packages and start the environment\n",
    "\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/).\n",
    "We also import our agent class and replay buffer class from `ddpg_agent.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ddpg_agent import Agent\n",
    "from ddpg_agent import ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiate agent and replay buffer\n",
    "\n",
    "We used one agent for both player and one shared replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=Agent(state_size=state_size, action_size=action_size, random_seed=2)\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "replay_buffer=ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the agent\n",
    "\n",
    "We defined a function `ddpg` to perform training of the agent. \n",
    "\n",
    "During training, both players are represented by the same agent. At each step, each player receive the state and return a action based on the agent's local actor network. Then both actions are passed to the environment and the environment outputs the next state, reward and whether the episode is finished. After each step, the two experiences from two players are added to the shared replay buffer.\n",
    "\n",
    "For stability of training, the actor and critic networks are only updated every certain steps. Here we used `update_every` of 5, meaning the networks are updated every 5 steps. When the networks are updated, the agent takes a random sample from the replay buffer and takes a learning step. \n",
    "\n",
    "During the training, we track the higher score out of the two scores for the 2 players for each episode. We consider the training is done once the average score of the most recent 100 episodes is higher than 0.5. We save the weight of the agent to `checkpoint_actor.pth` and `checkpoint_critic.pth` so that it can be loaded in the future. The score of each episode is plotted as well for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bchao\\AppData\\Local\\Continuum\\anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "D:\\udacity_DRL\\Collaboration_and_Competition\\ddpg_agent.py:104: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(self.critic_local.parameters(),1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20\tScore: 0.01\n",
      "Episode 40\tScore: 0.01\n",
      "Episode 60\tScore: 0.00\n",
      "Episode 80\tScore: 0.01\n",
      "Episode 100\tScore: 0.01\n",
      "Episode 120\tScore: 0.01\n",
      "Episode 140\tScore: 0.01\n",
      "Episode 160\tScore: 0.01\n",
      "Episode 180\tScore: 0.01\n",
      "Episode 200\tScore: 0.00\n",
      "Episode 220\tScore: 0.00\n",
      "Episode 240\tScore: 0.00\n",
      "Episode 260\tScore: 0.00\n",
      "Episode 280\tScore: 0.00\n",
      "Episode 300\tScore: 0.00\n",
      "Episode 320\tScore: 0.00\n",
      "Episode 340\tScore: 0.00\n",
      "Episode 360\tScore: 0.00\n",
      "Episode 380\tScore: 0.00\n",
      "Episode 400\tScore: 0.00\n",
      "Episode 420\tScore: 0.00\n",
      "Episode 440\tScore: 0.00\n",
      "Episode 460\tScore: 0.00\n",
      "Episode 480\tScore: 0.00\n",
      "Episode 500\tScore: 0.00\n",
      "Episode 520\tScore: 0.00\n",
      "Episode 540\tScore: 0.00\n",
      "Episode 560\tScore: 0.00\n",
      "Episode 580\tScore: 0.00\n",
      "Episode 600\tScore: 0.00\n",
      "Episode 620\tScore: 0.00\n",
      "Episode 640\tScore: 0.00\n",
      "Episode 660\tScore: 0.00\n",
      "Episode 680\tScore: 0.00\n",
      "Episode 700\tScore: 0.00\n",
      "Episode 720\tScore: 0.00\n",
      "Episode 740\tScore: 0.00\n",
      "Episode 760\tScore: 0.00\n",
      "Episode 780\tScore: 0.00\n",
      "Episode 800\tScore: 0.00\n",
      "Episode 820\tScore: 0.00\n",
      "Episode 840\tScore: 0.00\n",
      "Episode 860\tScore: 0.00\n",
      "Episode 880\tScore: 0.00\n",
      "Episode 900\tScore: 0.01\n",
      "Episode 920\tScore: 0.02\n",
      "Episode 940\tScore: 0.03\n",
      "Episode 960\tScore: 0.05\n",
      "Episode 980\tScore: 0.06\n",
      "Episode 1000\tScore: 0.06\n",
      "Episode 1020\tScore: 0.07\n",
      "Episode 1040\tScore: 0.06\n",
      "Episode 1060\tScore: 0.06\n",
      "Episode 1080\tScore: 0.05\n",
      "Episode 1100\tScore: 0.05\n",
      "Episode 1120\tScore: 0.05\n",
      "Episode 1140\tScore: 0.05\n",
      "Episode 1160\tScore: 0.05\n",
      "Episode 1180\tScore: 0.06\n",
      "Episode 1200\tScore: 0.07\n",
      "Episode 1220\tScore: 0.06\n",
      "Episode 1240\tScore: 0.06\n",
      "Episode 1260\tScore: 0.06\n",
      "Episode 1280\tScore: 0.08\n",
      "Episode 1300\tScore: 0.08\n",
      "Episode 1320\tScore: 0.10\n",
      "Episode 1340\tScore: 0.12\n",
      "Episode 1360\tScore: 0.12\n",
      "Episode 1380\tScore: 0.12\n",
      "Episode 1400\tScore: 0.12\n",
      "Episode 1420\tScore: 0.12\n",
      "Episode 1440\tScore: 0.13\n",
      "Episode 1460\tScore: 0.18\n",
      "Episode 1480\tScore: 0.20\n",
      "Episode 1500\tScore: 0.20\n",
      "Episode 1520\tScore: 0.21\n",
      "Episode 1540\tScore: 0.20\n",
      "Episode 1560\tScore: 0.14\n",
      "Episode 1580\tScore: 0.11\n",
      "Episode 1600\tScore: 0.11\n",
      "Episode 1620\tScore: 0.10\n",
      "Episode 1640\tScore: 0.10\n",
      "Episode 1660\tScore: 0.10\n",
      "Episode 1680\tScore: 0.11\n",
      "Episode 1700\tScore: 0.11\n",
      "Episode 1720\tScore: 0.12\n",
      "Episode 1740\tScore: 0.11\n",
      "Episode 1760\tScore: 0.11\n",
      "Episode 1780\tScore: 0.11\n",
      "Episode 1800\tScore: 0.11\n",
      "Episode 1820\tScore: 0.11\n",
      "Episode 1840\tScore: 0.12\n",
      "Episode 1860\tScore: 0.13\n",
      "Episode 1880\tScore: 0.12\n",
      "Episode 1900\tScore: 0.14\n",
      "Episode 1920\tScore: 0.23\n",
      "Episode 1940\tScore: 0.29\n",
      "Episode 1960\tScore: 0.34\n",
      "Episode 1980\tScore: 0.39\n",
      "Episode 2000\tScore: 0.44\n",
      "Episode 2020\tScore: 0.42\n",
      "Episode 2040\tScore: 0.39\n",
      "Episode 2060\tScore: 0.41\n",
      "Episode 2080\tScore: 0.47\n",
      "Episode 2100\tScore: 0.47\n",
      "Episode 2120\tScore: 0.42\n",
      "Episode 2140\tScore: 0.39\n",
      "Episode 2160\tScore: 0.33\n",
      "Episode 2180\tScore: 0.23\n",
      "Episode 2200\tScore: 0.17\n",
      "Episode 2220\tScore: 0.16\n",
      "Episode 2240\tScore: 0.15\n",
      "Episode 2260\tScore: 0.16\n",
      "Episode 2280\tScore: 0.15\n",
      "Episode 2300\tScore: 0.16\n",
      "Episode 2320\tScore: 0.25\n",
      "Episode 2340\tScore: 0.31\n",
      "Episode 2360\tScore: 0.39\n",
      "Episode 2380\tScore: 0.41\n",
      "Episode 2400\tScore: 0.49\n",
      "\n",
      "Environment solved in 2303 episodes!\tAverage Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "def ddpg(n_episodes=4000, print_every=20,update_every=5):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_list = []\n",
    "    update=0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = [agent.act(states[i]) for i in range(num_agents)] # select an action (for each agent)\n",
    "            actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            \n",
    "            for i in range(num_agents):          \n",
    "                replay_buffer.add(states[i],actions[i],rewards[i],next_states[i],dones[i]) # Save experience / reward\n",
    "            \n",
    "            if (len(replay_buffer) > BATCH_SIZE) and (update % update_every==0):# Learn, if enough samples are available in memory\n",
    "                for i in range(num_agents):\n",
    "                    experiences = replay_buffer.sample()\n",
    "                    agent.learn(experiences, GAMMA)\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            update += 1\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "        scores_deque.append(np.max(scores))\n",
    "        scores_list.append(np.max(scores))\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "    return scores_list\n",
    "\n",
    "scores_list = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of each episode is plotted for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores_list)+1), scores_list)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
